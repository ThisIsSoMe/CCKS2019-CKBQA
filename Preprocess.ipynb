{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 链接在数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "read_con = pymysql.connect(host=\"192.168.126.143\",port = 3337,user='root', password='pjzhang', database='ccks_2019',charset='utf8')\n",
    "cur = read_con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize(sentence):\n",
    "    sentence = sentence.replace('•','·')\n",
    "    # 年月日\n",
    "    items = re.search(r\"(\\d{4}年\\d{2}月\\d{2}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-').replace('月','-').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "            \n",
    "    items = re.search(r\"(\\d{4}年\\d{1}月\\d{2}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-0').replace('月','-').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{4}年\\d{2}月\\d{1}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-').replace('月','-0').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{4}年\\d{1}月\\d{1}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-0').replace('月','-0').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "            \n",
    "    # 月日\n",
    "    items = re.search(r\"(\\d{2}月\\d{2}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('月','-').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{1}月\\d{2}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = '0' + item.replace('月','-').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{1}月\\d{1}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = '0' + item.replace('月','-0').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{2}月\\d{1}日)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('月','-0').replace('日','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    # 年月\n",
    "    items = re.search(r\"(\\d{4}年\\d{2}月)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-').replace('月','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    items = re.search(r\"(\\d{4}年\\d{1}月)\",sentence)\n",
    "    if items:\n",
    "        for item in items.groups():\n",
    "            item_ = item.replace('年','-0').replace('月','')\n",
    "            sentence = sentence.replace(item,item_)\n",
    "    return sentence\n",
    "\n",
    "sents = ['歌手赵雷在2011年8月7日发行了哪首歌？','哪些人出生在9月19日？','村上春树所写的哪本小说是在2009年5月出版的？']\n",
    "for sent in sents:\n",
    "    print(normalize(sent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始文件\n",
    "def read_raw(fn):\n",
    "    # 读取训练文件，返回问句，sql语句，答案的list\n",
    "    question_list = []\n",
    "    qindex_list = []\n",
    "    sql_list = []\n",
    "    answer_list = []\n",
    "    with open(fn,'r',encoding='utf-8') as f:\n",
    "        context=f.read()\n",
    "    one_data=context.split('\\n\\n')\n",
    "    for one in one_data:\n",
    "        one=one.strip()\n",
    "        if not one:\n",
    "            continue\n",
    "        question,sql,answer=one.split('\\n')\n",
    "        q_index = question[1:question.index(':')]\n",
    "        question=question[question.index(':')+1:]\n",
    "        question = normalize(question)\n",
    "        sql=sql\n",
    "        answer=[i.strip() for i in answer.strip().split('\\t') if i.strip() ]\n",
    "        question_list.append(question)\n",
    "        qindex_list.append(q_index)\n",
    "        sql_list.append(sql)\n",
    "        answer_list.append(answer)\n",
    "    return qindex_list,question_list,sql_list,answer_list\n",
    "\n",
    "qindex_list,question_list,sql_list,answer_list = read_raw(\"data/test.txt\")\n",
    "question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取文件及处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sql2ent(sql):\n",
    "    #patterns=[re.compile(r'{\\s?<(.*?)>'),re.compile(r' <(.*?)>\\.'),re.compile(r'\\.\\s?<(.*?)>'),re.compile(r'\"(.*)\"')]\n",
    "    entities=[]\n",
    "    tmp=sql.split('where')\n",
    "    if len(tmp)==2:\n",
    "        sql=tmp[1]\n",
    "    elif len(tmp)==1:\n",
    "        sql=sql.split('WHERE')[1]\n",
    "        \n",
    "    #sql_part=sql.split('.')\n",
    "    sql_part=re.split(r'(>|[a-z]|\")\\s?\\.',sql)\n",
    "    #print(sql_part)\n",
    "    #patterns=[re.compile(r'<.*?>\\s<(.*?)>\\s?\\.'),re.compile(r'\\?\\w\\s<.*?>\\s<(.*?)>'),re.compile(r'\"(.*?)\"')]\n",
    "    #patterns=[re.compile(r'(<.*?>)\\s<.*?>\\s\\?\\s?'),re.compile(r'\\?\\w\\s<.*?>\\s(.*?)\\s?\\.'),re.compile(r\"'(.*?)'\"),re.compile(r'“(.*?)”')]\n",
    "    #patterns=[re.compile(r'(<.*?>)\\s<.*?>\\s\\?\\s?'),re.compile(r'\\?\\w\\s<.*?>\\s(.*?)\\s?\\.')]\n",
    "    p1 = re.compile(r'(<.*?>)\\s<.*?>\\s\\?')  # <Y> <R> ?x\n",
    "    p2 = re.compile(r'\\?\\w\\s<.*?>\\s(<.*)') # ?x <R> <Y>.\n",
    "    p3 = re.compile(r'\\?\\w\\s<.*?>\\s(\".*)')   # ?x <R> \"\" \n",
    "    p4 = re.compile(r'\\?\\w\\s\\?\\w\\s(<.*)')   # ?x ?x <A>\n",
    "    p5 = re.compile(r'(<.*?>)\\s\\?\\w\\s(<.*)')   # <A> ?x <B>\n",
    "    p6 = re.compile(r'(<.*?>)\\s\\?\\w\\s\\?')   # <A> ?x ?x\n",
    "    p7 = re.compile(r'filter regex\\(\\?\\w, (\".*?\")\\)')\n",
    "    p8 = re.compile(r\"filter regex\\(\\?\\w, ('.*?')\\)\")\n",
    "    patterns=[p1, p2, p3, p4, p5, p6, p7, p8]\n",
    "    #print(sql_part)\n",
    "    for sql_item in sql_part:\n",
    "        for pattern in patterns:\n",
    "            #tuples=pattern.findall(sql_item+'.')\n",
    "            tuples=pattern.findall(sql_item)\n",
    "            #print(sql_item+'.')\n",
    "            #print('tuples',tuples)\n",
    "            for es in tuples:\n",
    "                if not isinstance(es,tuple):\n",
    "                    entities.append(es)\n",
    "                    #entities.append(es.split(' ')[-1])\n",
    "                    continue\n",
    "                for e in es:\n",
    "                    entities.append(e)\n",
    "    entities=list(set(entities))\n",
    "    out=[]\n",
    "    for e in entities:\n",
    "        if not e:\n",
    "            continue\n",
    "        elif e[0]=='<' :\n",
    "            if e[-1]!='>':\n",
    "                out.append(e+'>')\n",
    "            else:\n",
    "                out.append(e)\n",
    "        elif e[0]=='\"' :\n",
    "            if e[-1]!='\"':\n",
    "                out.append(e+'\"')\n",
    "            else:\n",
    "                out.append(e)\n",
    "        elif e[0]==\"'\":\n",
    "            if e[-1]!=\"'\":\n",
    "                out.append(e+\"'\")\n",
    "            else:\n",
    "                out.append(e)\n",
    "    return out\n",
    "\n",
    "# def seq2ent2(sql):\n",
    "#     entities=[]\n",
    "#     sql=sql.split('where')[1]\n",
    "#     p1 = re.compile(r'(<.*?>)\\s<.*?>\\s\\?\\w')  # <Y> <R> ?x\n",
    "#     p2 = re.compile(r'\\?\\w\\s<.*?>\\s(<.*?>)\\.') # ?x <R> <Y>.\n",
    "#     p3 = re.compile(r'\\?\\w\\s<.*?>\\s\"(.*?)\"\\.')   # ?x <R> \"\" \n",
    "#     p4 = re.compile(r'\\?\\w\\s\\?\\w\\s(<.*?>)\\.')   # ?x ?x <A>\n",
    "#     p5 = re.compile(r'(<.*?>)\\s\\?\\w\\s(<.*?>)\\.')   # <A> ?x <B>\n",
    "#     p6 = re.compile(r'(<.*?>)\\s\\?\\w\\s\\?\\w\\.')   # <A> ?x ?x\n",
    "#     p7 = re.compile(r'filter regex\\(\\?\\w, \"(.*?)\"\\)')\n",
    "#     p8 = re.compile(r\"filter regex\\(\\?\\w, '(.*?)'\\)\")\n",
    "#     patterns=[p1, p2, p3, p4, p5, p6, p7, p8]\n",
    "#     for pattern in patterns:\n",
    "#         tuples=pattern.findall(sql)\n",
    "#         for es in tuples:\n",
    "#             if not isinstance(es,tuple):\n",
    "#                 entities.append(es)\n",
    "#                 continue\n",
    "#             for e in es:\n",
    "#                 entities.append(e)\n",
    "#     entities=list(set(entities))\n",
    "#     #print(entities)\n",
    "#     #entities=[e for e in entities if e and (e[0]=='<' or e[0]=='\"') ]\n",
    "#     out=[]\n",
    "#     for e in entities:\n",
    "#         if not e:\n",
    "#             continue\n",
    "#         elif e[0]=='<' :\n",
    "#             if e[-1]!='>':\n",
    "#                 out.append(e+'>')\n",
    "#             else:\n",
    "#                 out.append(e)\n",
    "#         elif e[0]=='\"' :\n",
    "#             if e[-1]!='\"':\n",
    "#                 out.append(e+'\"')\n",
    "#             else:\n",
    "#                 out.append(e)\n",
    "#         elif e[0]==\"'\":\n",
    "#             if e[-1]!=\"'\":\n",
    "#                 out.append(e+\"'\")\n",
    "#             else:\n",
    "#                 out.append(e)\n",
    "#     return out\n",
    "\n",
    "# sql里实体位置的内容\n",
    "def sql2ent2(sql):\n",
    "    entities=[]\n",
    "    if 'where' in sql:\n",
    "        sql=sql.split('where')[1]\n",
    "    else:\n",
    "        sql=sql.split('WHERE')[1]\n",
    "    p1 = re.compile(r'{\\s{0,2}(<.*?>)\\s<.*?>\\s\\?\\w\\s?\\.')  # <Y> <R> ?x\n",
    "    p1_ = re.compile(r'\\.\\s{0,2}(<.*?>)\\s<.*?>\\s\\?\\w\\s?\\.')  # <Y> <R> ?x\n",
    "    p2 = re.compile(r'\\?\\w\\s<.*?>\\s(<.*?>)\\s?\\.') # ?x <R> <Y>\n",
    "    p3 = re.compile(r'\\?\\w\\s<.*?>\\s(\".*?\")\\s?\\.')   # ?x <R> \"\" \n",
    "    p4 = re.compile(r'\\?\\w\\s\\?\\w\\s(<.*?>)\\s?\\.')   # ?x ?x <A>\n",
    "    p5 = re.compile(r'(<.*?>)\\s\\?\\w\\s(<.*?>)\\s?\\.')   # <A> ?x <B>\n",
    "    p6 = re.compile(r'(<.*?>)\\s\\?\\w\\s\\?\\w\\s?\\.')   # <A> ?x ?x\n",
    "    p7 = re.compile(r'filter regex\\(\\?\\w, (\".*?\")\\)')\n",
    "    p8 = re.compile(r\"filter regex\\(\\?\\w, ('.*?')\\)\")\n",
    "    p9 = re.compile(r\"('.*?')\")\n",
    "    p10 = re.compile(r'(\".*?\")')\n",
    "    patterns=[p1, p1_, p2, p3, p4, p5, p6, p7, p8, p9, p10]\n",
    "    for pattern in patterns:\n",
    "        tuples=pattern.findall(sql)\n",
    "        #print(tuples)\n",
    "        for es in tuples:\n",
    "            if not isinstance(es,tuple):\n",
    "                entities.append(es)\n",
    "                continue\n",
    "            for e in es:\n",
    "                entities.append(e)\n",
    "    entities=list(set(entities))\n",
    "    #print(entities)\n",
    "    #entities=[e for e in entities if e and (e[0]=='<' or e[0]=='\"') ]\n",
    "    out=[]\n",
    "    for e in entities:\n",
    "        if not e:\n",
    "            continue\n",
    "        elif e[0]=='<' :\n",
    "            if e[-1]!='>':\n",
    "                out.append(e+'>')\n",
    "            else:\n",
    "                out.append(e)\n",
    "        elif e[0]=='\"' :\n",
    "            if e[-1]!='\"':\n",
    "                out.append(e+'\"')\n",
    "            else:\n",
    "                out.append(e)\n",
    "        elif e[0]==\"'\":\n",
    "            if e[-1]!=\"'\":\n",
    "                out.append(e+\"'\")\n",
    "            else:\n",
    "                out.append(e)\n",
    "        else:\n",
    "            out.append(e)\n",
    "    return out\n",
    "\n",
    "# sql 里的有意义字符\n",
    "def sql2seq(sql):\n",
    "    tmp=sql.split('where')\n",
    "    if len(tmp)==2:\n",
    "        sql=tmp[1]\n",
    "    elif len(tmp)==1:\n",
    "        sql=sql.split('WHERE')[1]\n",
    "    \n",
    "    pattern=re.compile(r'(<.*?>|\".*?\"|\\'.*?\\')')\n",
    "    items=pattern.findall(sql)\n",
    "    return items\n",
    "    \n",
    "def entity_data(sql_list):\n",
    "    entities_list=[]\n",
    "    for sql in sql_list:\n",
    "        entities=sql2ent2(sql)\n",
    "        entities_list.append(entities)\n",
    "    return entities_list\n",
    "\n",
    "def rel_data(sql_list):\n",
    "    tri_list=[]\n",
    "    for sql in sql_list:\n",
    "        tri=sql2seq(sql)\n",
    "        tri_list.append(tri)\n",
    "    return tri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2ent2('select ?x where {  <秦淮八艳_（明末清初秦淮河畔八位名伎）> <本名> ?x . }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取sql语句中有意义的字符串，包括头尾实体及关系，按sql语句中出现的顺序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"valid\"# 'train','dev','test'\n",
    "fn=\"data/%s.txt\"%mode\n",
    "qindex_list,q_list,s_list,a_list=read_raw(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取实体\n",
    "e_list=entity_data(s_list)\n",
    "not_found=0\n",
    "not_found_index=[]\n",
    "for index,i in enumerate(e_list):\n",
    "    if not i:\n",
    "        not_found+=1\n",
    "        not_found_index.append(index)\n",
    "    print(index,i)\n",
    "print(\"not found:\",not_found)\n",
    "print(\"error question index:\")\n",
    "print(not_found_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取关系\n",
    "rel_list=rel_data(s_list)\n",
    "not_found=0\n",
    "not_found_index=[]\n",
    "for index,i in enumerate(rel_list):\n",
    "    if not i:\n",
    "        not_found+=1\n",
    "        not_found_index.append(index)\n",
    "    print(index,i)\n",
    "print(\"not found:\",not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取mention\n",
    "def load_mention(cur,q_list,e_list):\n",
    "    mention_list=[]\n",
    "    for index,es in enumerate(e_list):\n",
    "        mention=[]\n",
    "        if not es:\n",
    "            mention_list.append([])\n",
    "            continue\n",
    "        for item in es:\n",
    "            if item[0]=='\"' or item[0]==\"'\":\n",
    "                if item[1:-1] in q_list[index]:\n",
    "                    mention.append(item[1:-1])\n",
    "            else:\n",
    "                cand=search_alias(item[1:-1],cur)\n",
    "                cand.append(del_des(item)[1:-1])\n",
    "                cand.append(item[1:-1])\n",
    "                tmp=[c for c in cand if c in q_list[index]]\n",
    "                tmp=sorted(tmp,key=lambda x:len(x),reverse=True)\n",
    "#             from ipdb import set_trace\n",
    "#             set_trace()\n",
    "                if not tmp:\n",
    "                    mention.append([])\n",
    "                else:\n",
    "                    mention.append(tmp[0])\n",
    "        mention_list.append(mention)\n",
    "    return mention_list\n",
    "\n",
    "mention_list=load_mention(cur,q_list,e_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_unuse=0\n",
    "for i, items in enumerate(mention_list):\n",
    "    if not items or [] in items:\n",
    "        num_unuse+=1\n",
    "        print(q_list[i],s_list[i],e_list[i])\n",
    "        print('-'*30)\n",
    "num_unuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patternHead=re.compile(r'(\\?[a-z]) <.*?> \"|<')\n",
    "# patternHead=re.compile(r'\\?[a-z] <')\n",
    "# patternHead.findall('{ <青城派_（金庸小说中的门派）> ?x <掌门人>  . ?x <号称> \"三峡以西剑法第一\" . }')\n",
    "del_des('<舒杰_(维力医疗高管)>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问句根据sparql进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fn_out=\"data/classes_questions/%s\"%mode+\"_问句类型%s.txt\"\n",
    "patternVar=re.compile(r'(\\?[a-z])')\n",
    "patternHead=re.compile(r'(\\?[a-z]) <')\n",
    "patternRel=re.compile(r'> (\\?[a-z]) <')\n",
    "patternTail=re.compile(r'(\\?[a-z])(?:\\.| \\.)')\n",
    "\n",
    "p7 = re.compile(r'filter regex\\(\\?\\w, (\".*?\")\\)')\n",
    "p8 = re.compile(r\"filter regex\\(\\?\\w, ('.*?')\\)\")\n",
    "\n",
    "num_q=0\n",
    "num_one=0\n",
    "num_one_head=0 # 尾->头\n",
    "num_one_rel=0 # 找关系\n",
    "num_one_tail=0 # 头->尾\n",
    "num_two=0\n",
    "num_three=0\n",
    "num_multi=0\n",
    "num_two_tail0=0 # 样式一（双尾找一头）\n",
    "num_two_tail1=0 # 样式二（找中间）\n",
    "num_two_tail2=0 # 样式三（双头找一尾）\n",
    "pattern1=0 # 样式四（链式找尾实体）\n",
    "pattern2=0 # 样式六（三尾找一头）\n",
    "pattern3=0 # 样式七（三头找一尾）\n",
    "pattern4=0 # 样式五（尾-头-尾)\n",
    "pattern_new=0 # 新样式（头尾头）\n",
    "f_type=''\n",
    "data=''\n",
    "with open(fn,'r',encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        \n",
    "        if line[0].lower()=='s':\n",
    "            line=line.strip()\n",
    "            if 'where' in line:\n",
    "                line=line.split('where')\n",
    "                prefix = line[0]\n",
    "                line=line[1]\n",
    "            elif 'WHERE' in line:\n",
    "                line=line.split('WHERE')\n",
    "                prefix = line[0]\n",
    "                line=line[1]\n",
    "            else:\n",
    "                print('error')\n",
    "#             data+=line.strip()\n",
    "#             data+='\\n'\n",
    "            num_q+=1\n",
    "            \n",
    "#             if num_q ==2297:\n",
    "#                 from pdb import set_trace\n",
    "#                 set_trace()\n",
    "            \n",
    "            l=patternVar.findall(line)\n",
    "            count=len(l)\n",
    "            \n",
    "            if len(patternVar.findall(prefix))>1:\n",
    "                f_type=\"0\"\n",
    "            \n",
    "            elif p7.findall(line) or p8.findall(line) or 'UNION' in line or 'union' in line or 'filter' in line or 'regex' in  line:\n",
    "                num_multi+=1\n",
    "                f_type=\"0\"\n",
    "                \n",
    "            elif count==1:\n",
    "                num_one+=1\n",
    "                num_e = len(patternRel.findall(line))\n",
    "                if num_e == 1:\n",
    "                    num_one_rel += 1\n",
    "                    f_type='3' #\"两头找关系\"\n",
    "                    continue\n",
    "                num_e=len(patternHead.findall(line))\n",
    "                if num_e==1:\n",
    "                    num_one_head+=1\n",
    "                    f_type='2' #\"尾找头\"\n",
    "                    continue\n",
    "                num_e=len(patternTail.findall(line))\n",
    "                if num_e==1:\n",
    "                    num_one_tail+=1\n",
    "                    f_type='1' #\"头找尾\"\n",
    "                    continue\n",
    "            elif count==2:\n",
    "                num_tail=len(patternTail.findall(line))\n",
    "                num_two+=1\n",
    "                if num_tail==0:\n",
    "                    num_two_tail0+=1\n",
    "                    f_type='6' #\"双尾找一头\"\n",
    "                elif num_tail==1:\n",
    "                    num_two_tail1+=1\n",
    "                    f_type='8' #\"样式二（找中间）\"\n",
    "                elif num_tail==2:\n",
    "                    num_two_tail2+=1\n",
    "                    f_type='9' #\"样式三（双头找一尾）\"\n",
    "            elif count==3:\n",
    "                num_three+=1\n",
    "                num_tail = len(patternTail.findall(line))\n",
    "                num_head = len(patternHead.findall(line))\n",
    "                if len(set(l)) == 1:\n",
    "                      f_type='10'\n",
    "                elif num_head==1 and num_tail==2:\n",
    "                    pt=patternTail.findall(line)\n",
    "                    ph=patternHead.findall(line)\n",
    "                    if pt[0]==pt[1]:\n",
    "                        pattern_new+=1\n",
    "                        f_type='5' #\"新样式（头尾头）\"\n",
    "                    else:\n",
    "                        pattern1+=1\n",
    "                        f_type='4' #\"样式四（链式找尾实体）\"\n",
    "                elif num_head==3:\n",
    "                    pattern2+=1\n",
    "                    f_type='10' #\"样式六（三尾找一头）\"\n",
    "                elif num_tail==3:\n",
    "                    pattern3+=1\n",
    "                    f_type='10' #\"样式七（三头找一尾）\"\n",
    "                if num_head==2 and num_tail==1:\n",
    "                    pattern4+=1\n",
    "                    f_type='7' #\"样式五（尾-头-尾）\"\n",
    "            else:\n",
    "                num_multi+=1\n",
    "                f_type=\"0\"\n",
    "            \n",
    "        elif line[0].lower()==\"q\":\n",
    "            data+=line.strip()\n",
    "            pass\n",
    "        elif not line.strip():\n",
    "            data+=\"\\t%s\\n\"%f_type\n",
    "            with open(fn_out%f_type,'a',encoding='utf-8') as f_out:\n",
    "                f_out.write(data)\n",
    "                data=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取句子类型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取句子类型数据\n",
    "def load_type(num_case,num_type):\n",
    "    type_list=[0]*num_case\n",
    "    for i in range(1,num_type):\n",
    "        cur_fn = fn_out%i\n",
    "        if not os.path.exists(cur_fn):\n",
    "            continue\n",
    "        with open(cur_fn,'r') as f:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                if line:\n",
    "                    index=int(line[1:line.index(\":\")])-1\n",
    "                    type_list[index]=i\n",
    "    return type_list\n",
    "type_list=load_type(len(mention_list),11)\n",
    "assert len(q_list)==len(type_list)\n",
    "type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dict(qindex=None,q=None,sql=None,ans=None,ent=None,rel=None,mention=None,qtype=None):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存所有问句集中提取的信息\n",
    "import json\n",
    "assert(len(qindex_list)==len(e_list))\n",
    "assert(len(q_list)==len(e_list))\n",
    "assert(len(q_list)==len(rel_list))\n",
    "assert(len(q_list)==len(mention_list))\n",
    "all_data=(qindex_list,q_list,s_list,a_list,e_list,rel_list,mention_list,type_list)\n",
    "with open(\"data/%s.json\"%mode,'w')as f:\n",
    "    json.dump(all_data,f,ensure_ascii=False)\n",
    "print(\"output %s successful!\" % mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成NER训练文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#path = \n",
    "modes=[\"train\",\"valid\",'test']\n",
    "fn_out=\"NER/data/%s_bert_ner_input.txt\"\n",
    "\n",
    "for mode in modes:\n",
    "    fn = \"%s.json\"%mode\n",
    "    with open(fn,'r') as f:\n",
    "        cur_data = json.load(f)\n",
    "        question_label=[]\n",
    "        for q,ms in zip(cur_data[1],cur_data[6]):\n",
    "            if not ms or [] in ms:\n",
    "                continue\n",
    "            flag=False\n",
    "            for i in ms:\n",
    "                if isinstance(i,list):\n",
    "                    flag=True\n",
    "            if flag:\n",
    "                continue\n",
    "\n",
    "            label=['O']*len(q)\n",
    "            for m in ms:\n",
    "                start=q.index(m)\n",
    "                label[start]='B-'\n",
    "                if len(m)>1:\n",
    "                    for it in range(start+1,start+len(m)):\n",
    "                        label[it]='I-'\n",
    "            question_label.append((q,label))\n",
    "\n",
    "        with open(fn_out%mode,'w',encoding='utf-8') as f:\n",
    "            for q,l in question_label:\n",
    "                for a,b in zip(q,l):\n",
    "                    f.write(\"%s\\t%s\\n\"%(a,b))\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成test文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test' \n",
    "fn = \"%s.json\"%mode\n",
    "with open(fn,'r') as f:\n",
    "    cur_data = json.load(f)\n",
    "    questions_test = cur_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_out_test = fn_out%mode\n",
    "with open(fn_out_test,'w',encoding='utf-8') as fp:\n",
    "    for line in questions_test:\n",
    "        for word in line:\n",
    "            fp.write(\"%s\\tO\\n\"%(word))\n",
    "        fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "mode = 'train' \n",
    "fn = \"%s.json\"%mode\n",
    "with open(fn,'r') as f:\n",
    "    cur_data = json.load(f)\n",
    "    questions_test = cur_data[1]\n",
    "    mentions_test = cur_data[-2]\n",
    "    sql = cur_data[2]\n",
    "for q,m,s in zip(questions_test,mentions_test,sql):\n",
    "    if not m or [] in m:\n",
    "        #print(q,'\\t',m,'\\t',s)\n",
    "        pass\n",
    "    else:\n",
    "        print(q,'\\t',m,'\\t',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}